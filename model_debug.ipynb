{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99bb60da-0cc8-43a1-b300-013a83b9a4df",
   "metadata": {},
   "source": [
    "# Faster RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f15861-9e48-4a6f-a88b-bf689ea0b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "from flame.core.model.maskRCNN.faster_rcnn import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from flame.core.model.maskRCNN.faster_rcnn import fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
    "\n",
    "# device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# samples (for both mode, eval and train)\n",
    "images = [\n",
    "    cv2.imread('/home/phungpx/Downloads/dog.jpg'),\n",
    "    cv2.imread('/home/phungpx/Downloads/cat.jpg'),\n",
    "]\n",
    "\n",
    "samples: List[torch.Tensor] = []\n",
    "for image in images:\n",
    "    sample = torch.from_numpy(image).to(device)\n",
    "    sample = sample.float().div(255.)\n",
    "    sample = sample.permute(2, 0, 1)\n",
    "    samples.append(sample)\n",
    "\n",
    "# targets (for training mode)\n",
    "targets: List[Dict[str, torch.Tensor]] = [\n",
    "    {\n",
    "        'labels': torch.tensor([18], dtype=torch.int64, device=device),\n",
    "        'boxes': torch.tensor([[475,  43, 907, 566]], dtype=torch.float32, device=device),\n",
    "    },\n",
    "    {\n",
    "        'labels': torch.tensor([17], dtype=torch.int64, device=device),\n",
    "        'boxes': torch.tensor([[43,  47, 700, 672]], dtype=torch.float32, device=device),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1ecb60-ce1f-4dbb-99c9-bec7b5a49e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 19327458\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = fasterrcnn_mobilenet_v3_large_fpn(\n",
    "    weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1,\n",
    "    box_score_thresh=0.2,\n",
    "    box_nms_thresh=0.2,\n",
    ")\n",
    "\n",
    "print(f'Params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8330817-b6ff-4868-9301-f9c3f34e8dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation time: 1.1534547805786133s\n",
      "predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phungpx/anaconda3/envs/vtcc/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755883846/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[473.4747,  45.6446, 908.4516, 567.7006]]),\n",
       "  'labels': tensor([18]),\n",
       "  'scores': tensor([0.9831])},\n",
       " {'boxes': tensor([[ 43.1124,  46.5310, 699.1204, 671.2537]]),\n",
       "  'labels': tensor([17]),\n",
       "  'scores': tensor([0.9989])}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation mode\n",
    "model.eval().to(device)\n",
    "\n",
    "t1 = time.time()\n",
    "with torch.no_grad():\n",
    "    preds = model(samples)\n",
    "t2 = time.time()\n",
    "\n",
    "print(f'evaluation time: {t2 - t1}s')\n",
    "print('predictions:')\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ac8c55-1eb1-451b-bc03-14243ae3e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 1.0749309062957764s\n",
      "losses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(0.1329, grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(0.1349, grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.0031, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0.0414, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training mode\n",
    "model.train().to(device)\n",
    "\n",
    "t1 = time.time()\n",
    "losses = model(samples, targets)\n",
    "t2 = time.time()\n",
    "\n",
    "print(f'training time: {t2 - t1}s')\n",
    "print('losses:')\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464404a6-9253-434c-838c-266da78187b2",
   "metadata": {},
   "source": [
    "# MaskRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e7a826-f4fe-4a13-a430-c39f68a20169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "\n",
    "from flame.core.model.maskrcnn_resnet50_fpn_v2 import MaskRCNNResNet50FPNV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b750854-5645-405e-a42e-bde12b085f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 45883745\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "# model\n",
    "model = MaskRCNNResNet50FPNV2(\n",
    "    num_classes=3,\n",
    "    box_score_thresh=0.2,\n",
    "    box_nms_thresh=0.2,\n",
    ")\n",
    "\n",
    "print(f'Params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1887faa0-e6f6-4089-96aa-e450b056fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples\n",
    "samples: List[torch.Tensor] = [\n",
    "    torch.FloatTensor(size=(3, 800, 800), device=device),\n",
    "    # torch.FloatTensor(size=(3, 800, 1000), device=device),\n",
    "]\n",
    "\n",
    "# targets\n",
    "targets: List[Dict[str, torch.Tensor]] = [\n",
    "    {\n",
    "        'labels': torch.tensor([1], dtype=torch.int64, device=device),\n",
    "        'boxes': torch.tensor([[0, 0, 1, 1]], dtype=torch.float32, device=device),\n",
    "        'masks': torch.zeros(size=(1, 800, 800), device=device),\n",
    "    },\n",
    "    # {\n",
    "    #     'labels': torch.tensor([2], dtype=torch.int64, device=device),\n",
    "    #     'boxes': torch.tensor([[0, 0, 1, 1]], dtype=torch.float32, device=device),\n",
    "    #     'masks': torch.zeros(size=(1, 800, 1000), device=device),\n",
    "    # }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f7cdfb-7f2e-4710-b10a-568f3d000efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phungpx/anaconda3/envs/vtcc/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755883846/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbbbb\n",
      "training time: 1.518348217010498s\n",
      "losses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(1.0802, grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(9.6563e-06, grad_fn=<DivBackward0>),\n",
       " 'loss_mask': tensor(0.5961, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_objectness': tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0.9987, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training mode\n",
    "model.train().to(device)\n",
    "\n",
    "t1 = time.time()\n",
    "losses = model(samples, targets)\n",
    "t2 = time.time()\n",
    "\n",
    "print(f'training time: {t2 - t1}s')\n",
    "print('losses:')\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188957bd-f4c1-4f3f-8972-989e2b9e38c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+-----------+-----------------+------------------+\n",
      "| loss_classifier | loss_box_reg | loss_mask | loss_objectness | loss_rpn_box_reg |\n",
      "+-----------------+--------------+-----------+-----------------+------------------+\n",
      "|       nan       |     nan      |    nan    |       nan       |       nan        |\n",
      "+-----------------+--------------+-----------+-----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "verbose = PrettyTable(losses.keys())  # heading of table\n",
    "verbose.add_row([loss.item() for loss in losses.values()])\n",
    "print(verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32e175-4314-477f-aa46-8a6935c10f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
